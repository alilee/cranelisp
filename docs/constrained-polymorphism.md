# Constrained Polymorphism (Monomorphisation)

## Overview & Motivation

After adding `Float`, functions using trait operators like `+` become ambiguous when multiple impls exist (e.g., `Num Int` and `Num Float`). The expression `(defn foo [x y] (+ x y))` cannot be compiled because the typechecker doesn't know which `+` to dispatch to.

The fix: recognize that `foo` is a **constrained polymorphic function** — `foo :: (fn [:Num a a] a)` — and **monomorphise** it at call sites. `(foo 1 2)` compiles `foo$Int+Int`; `(foo 1.0 2.0)` compiles `foo$Float+Float`.

This is C++/Rust-style monomorphisation: constrained functions are templates that generate concrete specializations. No runtime overhead — fits cranelisp's static dispatch philosophy.

## Syntax

Constraints can be **inferred** from trait method usage within function bodies, or **explicitly annotated** on parameters using the `:Trait param` syntax:

```clojure
; Inferred — constraint detected from (+) usage
(defn add [x y] (+ x y))

; Annotated — equivalent, explicit constraint
(defn add [:Num x :Num y] (+ x y))
```

Both forms produce `add :: (fn [:Num a a] a)`. See `docs/syntax.md` for annotation details.

## Type Display

Constrained types use the `:Trait var` notation already established in `display.rs`:

```
foo :: (fn [:Num a a] a)
bar :: (fn [:Num :Eq a a] a)
```

## Type System

### Scheme with Constraints

`Scheme` gains a `constraints` field mapping quantified type variable IDs to the trait names they must satisfy:

```rust
pub struct Scheme {
    pub vars: Vec<TypeId>,
    pub constraints: HashMap<TypeId, Vec<String>>,
    pub ty: Type,
}
```

### Constraint Detection

During `infer_expr`, when a trait method is called on an unresolved type variable and multiple impls exist for that trait, the type variable gains a constraint instead of producing an error.

### Constraint Propagation

- **Unification**: when two type vars are unified, their constraints merge.
- **Instantiation**: when a constrained scheme is instantiated, constraints propagate to the fresh type variables.
- **Generalization**: constraints on quantified variables are preserved in the scheme.

## Resolution

### Deferred Resolution

When `resolve_operator_methods()` encounters an ambiguous type variable with multiple matching impls, it **defers** the resolution instead of erroring. The deferred resolution is stored alongside the function's constrained scheme for later per-specialization resolution.

### Per-Specialization Resolution

Each monomorphised variant gets its own `MethodResolutions` map. The same span (e.g., the `+` call in the function body) resolves to `+$Int` in `foo$Int+Int` but `+$Float` in `foo$Float+Float`.

## Monomorphisation

### Call-Site Specialization

When a constrained function is called with concrete types, a specialization is generated:

1. Map the scheme's type vars to the concrete argument types
2. Re-resolve deferred trait method calls with concrete types
3. Create a `Defn` with mangled name (e.g., `foo$Int+Int`)
4. Record a `SigDispatch` resolution at the call site

### Mangling

Uses existing `mangle_sig`: `foo$Int+Int`, `foo$Float+Float`.

### Iterative/Transitive Monomorphisation

If a constrained function calls another constrained function, the inner call generates additional monomorphisation requests. This is handled iteratively until no new requests remain.

## Code Generation

### Per-Specialization MethodResolutions

`FnCompiler` gains `fn_specific_resolutions: Option<&MethodResolutions>`. Resolution lookup checks this first, falling back to the global `method_resolutions`.

## Batch vs REPL

Both batch and REPL use the same on-demand monomorphisation approach:

1. After each definition is type-checked and overloads resolved, `monomorphise_all()` drains `pending_mono_calls` and returns `Vec<(MonoDefn, ModuleFullPath)>`.
2. Each `MonoDefn` is paired with its **defining module** — the module where the constrained function was originally defined.
3. `compile_mono_specializations()` (shared method on `ReplSession`) compiles each specialization into the defining module's GOT, ensuring cross-module callers resolve the specialization via the defining module's symbol table.
4. In batch mode, cache writes are deferred until after the entire compile loop, so that mono specializations generated by later modules are included in earlier modules' `.o` files.

There is no separate `mono.o` — all specializations live in their defining module's `.o` alongside the original function definitions.

## Examples

```lisp
; Define a constrained function
(defn add [x y] (+ x y))
; add :: (fn [:Num a a] a)

; Call with Int — generates add$Int+Int
(add 1 2)         ; => 3

; Call with Float — generates add$Float+Float
(add 1.0 2.0)     ; => 3.0
```

## Design Decisions

- **Monomorphisation over dictionary passing**: Zero runtime overhead, consistent with static dispatch philosophy. Dictionary passing would be needed for first-class constrained values, deferred to future work.
- **`SigDispatch` reuse**: Monomorphised function calls use the existing `SigDispatch` resolution variant.
- **Bare constrained fn as value is an error**: `(let [f add] ...)` where `add` is constrained produces an error — the concrete type must be known at the call site.

## Limitations

- Constrained functions cannot be used as first-class values (no dictionary passing yet).
- Constrained polymorphic closures as values are not supported.
- HKT trait methods (e.g., `fmap`) are **not** constrained polymorphic functions — they dispatch via the trait resolution path. Writing generic HKT code like `(defn map-inc [xs] (fmap inc xs))` is not yet supported. See `docs/hkt.md`.

## Future Extensions

- Dictionary passing for first-class constrained function values.
- Constraint inference for closures returned from constrained functions.
